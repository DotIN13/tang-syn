{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "华俊龙苦笑着说：“文晋，这不公平，你的\n",
      "都教一个班，外前教两个班；还是二年级，未\n",
      "免有失公道吧！”\n",
      "李文晋笑着说：“是不公平，这分工作总得\n",
      "有人去干吧？你说，该给谁干呢？我说说一句，\n",
      "他们就告诉我：这是教务科的安排。廖理长还\n",
      "说：你们一起奉旨华俊龙老师，领导看得他起\n",
      "就把拿起交给他了。”\n",
      "张厚生笑着说：“这叫程者多劳，你就担起\n",
      "这个仓担吧，有什么困难，我们都会帮忙好。”\n",
      "周宏文也说：“我们刚来，学校要掀工作，\n",
      "我们还是愉快地接受下来，不说什么为好。当\n",
      "让俊龙一个人任二年级好课，而且教两个班，\n",
      "如此何会辛苦许多。从另一方面说，也是学校\n",
      "对你的重视，不过，无论怎么说，还是辛苦考\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoTokenizer\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model_pth = \"models/checkpoint-53200/\"\n",
    "# model_pth = \"models/checkpoint-33600\"\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_pth)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_pth)\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "truth = \"\"\"\n",
    "test-niandai/1.png\t华俊龙苦笑着说：文晋，这不公平：你的\n",
    "test-niandai/2.png\t都教一个班，我却教两个班，还是二年级，未\n",
    "test-niandai/3.png\t免有失公道吧！\n",
    "test-niandai/4.png\t李文晋笑着说：“是不公平，这分工作总得\n",
    "test-niandai/5.png\t有人去干吧？你说，该给谁干呢？我没说一句，\n",
    "test-niandai/6.png\t他们就告诉我：这是教务科的安排。廖组长还\n",
    "test-niandai/7.png\t说：“你们一起来的华俊龙老师，领导者得他起，\n",
    "test-niandai/8.png\t就把重担交给他了。”\n",
    "test-niandai/9.png\t张厚生笑着说：“这叫能者多劳，你就担起\n",
    "test-niandai/10.png\t这个危险吧，有什么困难，我们都会帮忙的。”\n",
    "test-niandai/11.png\t周宏义也说：“我们刚来，学校安排工作，\n",
    "test-niandai/12.png\t我们还是愉快地接受下来，不说什么为好。当\n",
    "test-niandai/13.png\t然俊龙一个人任二年级的课，而且教两个班，\n",
    "test-niandai/14.png\t比我们辛苦许多，从另一方面说，也是学校\n",
    "test-niandai/15.png\t对你的重视，不过，无论怎么说，还是辛苦老\n",
    "\"\"\".strip().split(\"\\n\")\n",
    "\n",
    "test_dir = \"dataset/data/test-niandai\"\n",
    "# test_dir = \"samples/images\"\n",
    "for file in os.listdir(test_dir):\n",
    "    if not file.endswith((\".jpg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    # print(truth.pop(0))\n",
    "\n",
    "    image = Image.open(os.path.join(test_dir, file)).convert(\"RGB\")\n",
    "\n",
    "    pixel_values = (\n",
    "        processor(image, return_tensors=\"pt\").pixel_values).to(device)\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    generated_text = tokenizer.decode(\n",
    "        generated_ids[0], skip_special_tokens=True)\n",
    "    print(generated_text.replace(\" \", \"\"))\n",
    "\n",
    "# text = \"李文晋就走来了。他告诉大家说：“刚才我从廖\"\n",
    "# image = Image.open(os.path.join(\"sample_imgs\", \"0.png\")).convert(\"RGB\")\n",
    "# # print(processor.image_processor.to_dict())\n",
    "# pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "# labels = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "# # outputs = model(pixel_values, labels=labels)\n",
    "# outputs = model.generate(pixel_values)\n",
    "# generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "# print(labels, outputs, generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 872,\n",
       " 3221,\n",
       " 2769,\n",
       " 4638,\n",
       " 2207,\n",
       " 5741,\n",
       " 3362,\n",
       " 872,\n",
       " 3221,\n",
       " 2769,\n",
       " 4638,\n",
       " 1920,\n",
       " 5741,\n",
       " 107,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 102]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoTokenizer\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model_pth = \"models/tang-syn-2.0-checkpoint-374000\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_pth)\n",
    "\n",
    "input_ids = tokenizer(\"你是我的小苹果 你是我的大苹\\\"““”‘’\").input_ids\n",
    "input_ids\n",
    "# tokenizer.decode(input_ids)\n",
    "# tokenizer.decode([2, 17, 7158, 8884, 8884, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    labels_str = tokenizer.batch_decode(labels_ids,\n",
    "                                        skip_special_tokens=True)\n",
    "    \n",
    "    lines = map(lambda x: \"\\n\".join(x).replace(\" \", \"\"), zip(labels_str, pred_str))\n",
    "    print(\"\\n\\n\".join(lines))\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=labels_str)\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=labels_str)\n",
    "\n",
    "    return {\"cer\": cer, \"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-48900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing hwdb_ic13_3k.tsv\n",
      "Number of validation examples: 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "的情况不同，并没有硬性规定医院必须接受持卡居民刷卡体检。但从实施\n",
      "的情况不同，并没有硬性规定医院必须接受扩大居民到卡体检，但从\n",
      "\n",
      "刷医保卡可以体检了，这项惠民政策出台后，\n",
      "刷家保卡可以体验了，这次惠民政策出后，\n",
      "\n",
      "而所有“垃圾”都由彩色灯泡串连起来，忽明忽暗\n",
      "而所有“垃圾”都由彩色灯泡串绕起来，忽明忽目青\n",
      "\n",
      "问题的实质。\n",
      "问题的实质。\n",
      "\n",
      "或许可以实现他一生的梦想之一，那就是参加美国\n",
      "或许可以实现他一生的梦想之一，那就是参加美国\n",
      "\n",
      "西南、中南和东北五个地区，这样分配比\n",
      "西南、中南和东北五个地区，这样分配比\n",
      "\n",
      "独有的创作风格，其写意花鸟画造诣深厚，笔法酣畅\n",
      "独有的创作风格，具写意气息的造型深厚基础基\n",
      "\n",
      "着群猫从各个猫洞里冒出来涌上了舞台中央\n",
      "着群猎从各个猎洞里冒出来，涌上了舞台中央\n",
      "\n",
      "这部被誉为周星驰转型之作的电影保密工作滴水不漏，从\n",
      "这部被誉为国星驰转型之作的电影保密工作满水不漏，从\n",
      "\n",
      "多的受到世界的关注。\n",
      "多的受到世界的关注。\n",
      "\n",
      "宣传工作会议代表座谈。他强调，要从中国特色社会主义全局的战略高度，进一步增\n",
      "宣传工作会议代表座谈。他强调，要从中国特色社会主义全局的战略\n",
      "\n",
      "踢踏舞、凝重华丽的芭蕾舞以及充满动感的爵士\n",
      "踢踏舞，凝重华丽的芭蕾舞以及充满动感的爱与\n",
      "\n",
      "乔普拉的莱德杯世界积分（rydercupworldpoints）\n",
      "乔普拉的莱德.标世界荣誉号（1996）-cupworld品牌的\n",
      "\n",
      "细的研究，今年不会做调整。2009年高考方案跟今年一样，本身不会做\n",
      "细的研究，今年不到做调整。2009年高考录取工作一样，本身不会做\n",
      "\n",
      "在单打比赛中投入太多精力。彭帅与孙甜甜的双打组合已固定下来，她们\n",
      "在勒比赛中投入太多精力。彭帅与孙甜甜甜地对组合已固定下来，她\n",
      "\n",
      "回馈消费者长期以来的支持和关爱，西铁城在\n",
      "回馈，消费者长期以来的支持和关爱，而铁城在\n",
      "\n",
      "淳朴而又稳健洒脱，将写意“荷”的阳刚之美发挥的淋\n",
      "淳朴而又不急行速调节，将写意有“的阳刚之美发挥的淋\n",
      "\n",
      "其很看好，并在去年主动提出担任彭帅的教练。然而，彭帅在比赛中的发挥\n",
      "其很青好，并在去年主动提出担任彭师的教练，然而彭师在比赛中的\n",
      "\n",
      "准确，但实际上，电脑验光仪显示的数据只是一个\n",
      "准确，但实际上，电脑骗光的显示的数据只是一个\n",
      "\n",
      "正好把“压岁钱“放在里面。”此外，“福娃五福临门贺卡”“奥\n",
      "正好把“压岁钱”放在里面。”此外，“福娃”还福临门贺“海\n",
      "\n",
      "放在了76人的组织后卫安德烈-米勒身上，球队希望把他引进来与辛里奇组\n",
      "放在了伦敦的欧洲后卫队的一张录力单上，球队希望把他引进来与年\n",
      "\n",
      "位地关注消费者的各种需求，并秉承“以客户为中心”的服务理念，\n",
      "位地关注消费者的各种需求，并秉承“以客户为中心”的服务理念，\n",
      "\n",
      "损。专家分析认为，基金亏损的直接原因是大盘调整增加，投资者未来应根\n",
      "损。专家分析认为，基金亏损的直接原因是大盘调整增加，投资者未\n",
      "\n",
      "争的局面。为了兼顾永定河上下游地区\n",
      "争的局面。为了兼顾永定河上下游地区\n",
      "\n",
      "定了《国家奖学金评审办法》。教育部今天在其官方网站发布《国家奖学金\n",
      "定了《国家奖学金评审办法》。教育部今天在其官方网站发布《上国\n",
      "\n",
      "的想法没有多大改变，在赛季冬季转会截止日到来之前，\n",
      "的热点没有多大改变，在紧紧冬季就会截止日到来了前，\n",
      "\n",
      "民币汇率的大幅走强，令欧洲出口商十分头痛。与此同时，欧元对\n",
      "民币汇率的大幅走动，令欧洲出口商十分欣痛。与此同时，欧元对\n",
      "\n",
      "的走势来看，很多个股都属于突破下降通道后的\n",
      "的主势来看，很多个股都属于突破下降通道的\n",
      "\n",
      "就连华裔网球明星张德培都对其很看好，并在去\n",
      "就连华裔网球明星张德培都对其很着好，并在专\n",
      "\n",
      "备受观众期待的喜剧科幻大片《长江7号》将于本月31日\n",
      "备受观众期待的喜剧科幻大片《长江号》将于本月31日\n",
      "\n",
      "出口行业。美国次贷危机让众多央行纷纷下调其利率水平，其中包括美联\n",
      "出口行业。美国发展危机让众多央行纷纷调其利率水平，其中包括美\n",
      "\n",
      "改组，并更名为客户满意部，希望通过不懈的努力，\n",
      "欢组，并更名为客户满意部，希望通过不懈的努力，\n",
      "\n",
      "在国家散打队主教练张根学看来，中国散打目前最大的优势就是队员们的摔\n",
      "在国家级星评员换装先进学者来，中国制造目前最大的优势就是以及\n",
      "\n",
      "抓住问题的实质。\n",
      "抓住问题的实质。\n",
      "\n",
      "道路基本畅通，且路况较好，走福宁高速可以直接由福鼎出\n",
      "道路基本相通，且路况较好，走极少高速可以直接进行视野采\n",
      "\n",
      "1000部，非法经营额超过1000万元人民币，在国内\n",
      "10.02都非法经营额超过100万元人民币。在国内\n",
      "\n",
      "者的利益。另一个原因是消费者过度相信电脑验光仪，认为高科\n",
      "有的利益，另一个面因是调整存过度的投资习性及个人行为有所\n",
      "\n",
      "都还维持在5日均线上方，市场整体还是属于强势\n",
      "都还能存在50年以上，市场整体上是属于没有\n",
      "\n",
      "认，目前阶段还是处在稳步的上升通道内运行，只是近阶段涨幅\n",
      "认，目前的铅还是处在稳步的上升通道内进行，只要近阶段的长幅\n",
      "\n",
      "但实际上，电脑验光仪显示的数据只是一个参考值区间值，\n",
      "但实际上，电脑验光仪显示，线数据只是一个参考值，这间值\n",
      "\n",
      "析，公牛交易的主要筹码很可能是前锋泰瑞斯-托马斯。此外，公牛的主力得\n",
      "拆公牛交易的主要筹码很可能是前锋泰瑞斯-托马斯。此外，公牛的\n",
      "\n",
      "由新员工组成的引导岗位，负责带领旅客由值机大厅到航班不正常柜台\n",
      "田新建工组成的科学家组，负责带领考察队参加大厅到的各种不正常\n",
      "\n",
      "土机”，姚明的变化有目共睹，他已经将自己的统治力展现得\n",
      "土机”，姚明的变化有目共睹，他已经将自己的统治力展现得\n",
      "\n",
      "市医保中心对此解答：由于各家医院的情况不\n",
      "市医保中心对此解答：由于各家医院的情况不\n",
      "\n",
      "查办了有限的案件，达到了有限的目的，互联网领域中的侵权盗版问题还很\n",
      "查办了有限公案件，达到了有了公民的目的，互联网领域中的受权益\n",
      "\n",
      "一员而去美国肯塔基州的路易斯维尔瓦哈拉（valhalla）参赛或许\n",
      "一员而去美国肯塔基州的路易斯·维尔瓦哈娃（walhall）告诉\n",
      "\n",
      "沪苏浙高速公路江苏段日前正式建成通车，全线采用六车道标准设计\n",
      "沪苏浙高速公路的贯段目前已建成通车，全线采用六车道标准设计\n",
      "\n",
      "损伤，在接下来的两场比赛里他都不会上场。“我会让他休息几天处理好脚踝\n",
      "担任，在接下来的两场比赛里他都不会放弃。”我会让他们玩处理。\n",
      "{'eval_loss': 1.38434636592865, 'eval_cer': 0.14029975020815988, 'eval_wer': 0.2087821043910522, 'eval_runtime': 4.946, 'eval_samples_per_second': 9.705, 'eval_steps_per_second': 0.202}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from data_aug_v2 import build_data_aug\n",
    "# from torch.utils.data import Subset\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoTokenizer\n",
    "from transformers import default_data_collator\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "dataset_dir = 'dataset/data'\n",
    "max_length = 64\n",
    "\n",
    "\n",
    "def load_model(model_pth):\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(model_pth)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_pth)\n",
    "    processor = TrOCRProcessor.from_pretrained(\n",
    "        \"microsoft/trocr-base-handwritten\")\n",
    "    return model, tokenizer, processor\n",
    "\n",
    "\n",
    "class OCRDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset_dir,\n",
    "                 labels_dir,\n",
    "                 labels,\n",
    "                 transform,\n",
    "                 processor,\n",
    "                 tokenizer,\n",
    "                 mode=\"train\",\n",
    "                 max_target_length=32,\n",
    "                 device=None):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "        self.processor = processor\n",
    "        self.mode = mode\n",
    "        self.max_target_length = max_target_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = self.build_df()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Thirty percent of the time, use existing dataset\n",
    "        text = self.df['text'][idx]\n",
    "        # get file name + text\n",
    "        file_name = self.df[\"file_name\"][idx]\n",
    "        # prepare image (i.e. resize + normalize)\n",
    "        image = Image.open(path.join(self.dataset_dir,\n",
    "                                     file_name)).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "        # Remove spaces from text, as only the tang-syn version 1 had spaces before text\n",
    "        text = text.strip()\n",
    "        labels = self.tokenizer(text,\n",
    "                                padding=\"max_length\",\n",
    "                                stride=32,\n",
    "                                truncation=True,\n",
    "                                max_length=self.max_target_length).input_ids\n",
    "\n",
    "        # important: make sure that PAD tokens are ignored by the loss function\n",
    "        labels = [\n",
    "            label if label != self.tokenizer.pad_token_id else -100\n",
    "\n",
    "            for label in labels\n",
    "        ]\n",
    "\n",
    "        encoding = {\n",
    "            \"pixel_values\": pixel_values.squeeze(),\n",
    "            \"labels\": torch.tensor(labels)\n",
    "        }\n",
    "\n",
    "\n",
    "        return encoding\n",
    "\n",
    "    def build_df(self):\n",
    "        li = []\n",
    "        for root, _dirs, files in os.walk(self.labels_dir):\n",
    "            for file in files:  # Loop through the dataset tsvfiles\n",
    "                if not file.endswith(\".tsv\"):\n",
    "                    continue\n",
    "\n",
    "                if self.labels and file not in self.labels:\n",
    "                    continue\n",
    "\n",
    "                print(f\"Processing {file}\")\n",
    "                li.append(\n",
    "                    pd.read_table(path.join(root, file),\n",
    "                                  names=[\"file_name\", \"text\"]))\n",
    "\n",
    "        return pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "def build_eval_dataset(tokenizer, processor):\n",
    "    eval_dataset = OCRDataset(\n",
    "        dataset_dir=dataset_dir,\n",
    "        labels_dir=\"dataset/labels/test\",\n",
    "        labels=[\"hwdb_ic13_3k.tsv\"],\n",
    "        tokenizer=tokenizer,\n",
    "        processor=processor,\n",
    "        mode=\"eval\",\n",
    "        transform=build_data_aug(64, \"eval\"),\n",
    "        max_target_length=max_length\n",
    "    )\n",
    "\n",
    "    # Create a random subset of the dataset\n",
    "    num_samples = 48\n",
    "\n",
    "    subset_indices = torch.randperm(len(eval_dataset))[:num_samples]\n",
    "    eval_dataset = Subset(eval_dataset, subset_indices.tolist())\n",
    "\n",
    "    print(\"Number of validation examples:\", len(eval_dataset))\n",
    "    return eval_dataset\n",
    "\n",
    "\n",
    "def init_trainer(model, tokenizer, compute_metrics, train_dataset,\n",
    "                 eval_dataset):\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        predict_with_generate=True,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        per_device_train_batch_size=48,\n",
    "        per_device_eval_batch_size=48,\n",
    "        num_train_epochs=3,\n",
    "        fp16=True,\n",
    "        learning_rate=4e-5,\n",
    "        output_dir=\"./checkpoints\",\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=100,\n",
    "        save_strategy=\"steps\",\n",
    "        save_total_limit=5,\n",
    "        save_steps=10000,\n",
    "        eval_steps=10000,\n",
    "        resume_from_checkpoint=\"./checkpoints/\",\n",
    "        dataloader_num_workers=4)\n",
    "\n",
    "    # instantiate trainer\n",
    "    return Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=default_data_collator\n",
    "    )\n",
    "\n",
    "\n",
    "for pth in os.listdir(\"models\"):\n",
    "    model_pth = os.path.join(\"models\", pth)\n",
    "    if not os.path.isdir(model_pth) or pth == \"trocr-chinese-handwritten\":\n",
    "        continue\n",
    "    \n",
    "    if not pth == \"checkpoint-48900\":\n",
    "        continue\n",
    "\n",
    "    print(pth)\n",
    "\n",
    "    model, tokenizer, processor = load_model(model_pth)\n",
    "    eval_dataset = build_eval_dataset(tokenizer=tokenizer, processor=processor)\n",
    "    trainer = init_trainer(model, tokenizer, compute_metrics,\n",
    "                           eval_dataset, eval_dataset)\n",
    "    eval_result = None\n",
    "    with torch.no_grad():\n",
    "        eval_result = trainer.evaluate()\n",
    "    \n",
    "    print(eval_result)\n",
    "    \n",
    "    del model, tokenizer, processor\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tang-syn-1.0-checkpoint-280000\n",
    "\n",
    "{'eval_loss': 1.519798755645752, 'eval_cer': 0.40390193507370764, 'eval_wer': 0.6983321165833661, 'eval_runtime': 377.7759, 'eval_samples_per_second': 9.082, 'eval_steps_per_second': 0.191}\n",
    "\n",
    "\n",
    "tang-syn-2.0-checkpoint-374000\n",
    "\n",
    "{'eval_loss': 0.6802470684051514, 'eval_cer': 0.19505134274475078, 'eval_wer': 0.32816308193407084, 'eval_runtime': 369.2777, 'eval_samples_per_second': 9.291, 'eval_steps_per_second': 0.195}\n",
    "\n",
    "\n",
    "tang-syn-3.0-epoch-1\n",
    "\n",
    "{'eval_loss': 1.134255051612854, 'eval_cer': 0.1194216060379564, 'eval_wer': 0.18192635758054293, 'eval_runtime': 241.6356, 'eval_samples_per_second': 14.199, 'eval_steps_per_second': 0.298}\n",
    "\n",
    "\n",
    "checkpoint-30500\n",
    "\n",
    "{'eval_loss': 1.2217962741851807, 'eval_cer': 0.15558527826639168, 'eval_wer': 0.24539317845664527, 'eval_runtime': 326.8407, 'eval_samples_per_second': 10.497, 'eval_steps_per_second': 0.22}\n",
    "\n",
    "\n",
    "checkpoint-33600\n",
    "\n",
    "{'eval_loss': 1.1907786130905151, 'eval_cer': 0.14627320291557314, 'eval_wer': 0.23189243891860634, 'eval_runtime': 327.7571, 'eval_samples_per_second': 10.468, 'eval_steps_per_second': 0.22}\n",
    "\n",
    "\n",
    "checkpoint-51000\n",
    "\n",
    "{'eval_loss': 1.2108386754989624, 'eval_cer': 0.1494708920372483, 'eval_wer': 0.23515085463907207, 'eval_runtime': 327.8426, 'eval_samples_per_second': 10.465, 'eval_steps_per_second': 0.22}\n",
    "\n",
    "\n",
    "checkpoint-53200\n",
    "\n",
    "{'eval_loss': 1.1683052778244019, 'eval_cer': 0.13790526073249, 'eval_wer': 0.2147885366043527, 'eval_runtime': 327.9052, 'eval_samples_per_second': 10.463, 'eval_steps_per_second': 0.22}\n",
    "\n",
    "\n",
    "checkpoint-55400\n",
    "\n",
    "{'eval_loss': 1.1703541278839111, 'eval_cer': 0.13339252898432627, 'eval_wer': 0.20729306836000488, 'eval_runtime': 327.7568, 'eval_samples_per_second': 10.468, 'eval_steps_per_second': 0.22}\n",
    "\n",
    "\n",
    "checkpoint-48900\n",
    "\n",
    "{'eval_loss': 1.155460000038147, 'eval_cer': 0.13623616816810066, 'eval_wer': 0.21204168103112733, 'eval_runtime': 326.5331, 'eval_samples_per_second': 10.507, 'eval_steps_per_second': 0.22}\n",
    "\n",
    "\n",
    "checkpoint-57500\n",
    "\n",
    "{'eval_loss': 1.1646119356155396, 'eval_cer': 0.13455021608285891, 'eval_wer': 0.2093726715672646, 'eval_runtime': 325.7347, 'eval_samples_per_second': 10.533, 'eval_steps_per_second': 0.221}\n",
    "\n",
    "\n",
    "checkpoint-57600\n",
    "\n",
    "{'eval_loss': 1.1678860187530518, 'eval_cer': 0.13510096043070455, 'eval_wer': 0.21078502240855862, 'eval_runtime': 325.3876, 'eval_samples_per_second': 10.544, 'eval_steps_per_second': 0.221}\n",
    "\n",
    "\n",
    "checkpoint-57700\n",
    "\n",
    "{'eval_loss': 1.17428719997406, 'eval_cer': 0.13770294648226097, 'eval_wer': 0.21508880016903725, 'eval_runtime': 325.9386, 'eval_samples_per_second': 10.527, 'eval_steps_per_second': 0.221}\n",
    "\n",
    "checkpoint-57800\n",
    "\n",
    "{'eval_loss': 1.1709500551223755, 'eval_cer': 0.13650030066145522, 'eval_wer': 0.21267557077879473, 'eval_runtime': 325.8716, 'eval_samples_per_second': 10.529, 'eval_steps_per_second': 0.221}\n",
    "\n",
    "\n",
    "checkpoint-57900\n",
    "\n",
    "{'eval_loss': 1.1812629699707031, 'eval_cer': 0.13939451840778685, 'eval_wer': 0.21737969995885278, 'eval_runtime': 325.4088, 'eval_samples_per_second': 10.544, 'eval_steps_per_second': 0.221}\n",
    "\n",
    "\n",
    "checkpoint-58000\n",
    "\n",
    "{'eval_loss': 1.1745655536651611, 'eval_cer': 0.13741071478748573, 'eval_wer': 0.21382102067370248, 'eval_runtime': 325.7256, 'eval_samples_per_second': 10.533, 'eval_steps_per_second': 0.221}\n",
    "\n",
    "\n",
    "checkpoint-58100\n",
    "\n",
    "{'eval_loss': 1.1712112426757812, 'eval_cer': 0.13623616816810066, 'eval_wer': 0.21241979070517455, 'eval_runtime': 325.9611, 'eval_samples_per_second': 10.526, 'eval_steps_per_second': 0.221}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1712112426757812,\n",
       " 'eval_cer': 0.13623616816810066,\n",
       " 'eval_wer': 0.21241979070517455,\n",
       " 'eval_runtime': 315.1533,\n",
       " 'eval_samples_per_second': 10.887,\n",
       " 'eval_steps_per_second': 0.228}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats\n",
    "from pstats import SortKey\n",
    "p = pstats.Stats('0.log')\n",
    "p.strip_dirs().sort_stats(\"cumtime\").print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup fonts that does not support cjk\n",
    "\n",
    "import os\n",
    "import pygame\n",
    "import pygame.freetype\n",
    "from fontTools.ttLib import TTFont\n",
    "\n",
    "pygame.freetype.init()\n",
    "\n",
    "\n",
    "def get_font_names(font_path):\n",
    "    font = TTFont(font_path)\n",
    "    names = []\n",
    "    for record in font['name'].names:\n",
    "        if record.nameID == 4:\n",
    "            if record.getEncoding() == \"x_mac_simp_chinese_ttx\":\n",
    "                names.append(record.string.decode('gbk'))\n",
    "            else:\n",
    "                names.append(record.toStr())\n",
    "\n",
    "    return names\n",
    "\n",
    "\n",
    "for file in os.listdir(\"fonts\"):\n",
    "    if file.lower().endswith((\".ttf\", \".otf\")):\n",
    "        # font = pygame.freetype.Font(f\"fonts/{file}\", size=10)\n",
    "        # metrics = font.get_metrics(\"你是我的小苹果，我是你的大苹果！\")\n",
    "\n",
    "        # invalid_metrics = not all(metrics)\n",
    "\n",
    "        names = get_font_names(f\"fonts/{file}\")\n",
    "        invalid_type = any(\"篆\" in font_name or (\n",
    "            \"繁\" in font_name and \"简\" not in font_name) for font_name in names)\n",
    "\n",
    "        if invalid_type:\n",
    "            # print(names)\n",
    "            os.rename(f\"fonts/{file}\", f\"fonts/archives/{file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
