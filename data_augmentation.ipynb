{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "LABELS_DIR = \"labels\"\n",
    "DATA_DIR = \"data\"\n",
    "AUG_DIR = \"aug\"\n",
    "\n",
    "if path.exists(AUG_DIR):\n",
    "    os.rmdir(AUG_DIR)\n",
    "\n",
    "for root, dirs, files in os.walk(DATA_DIR):\n",
    "    for dir in dirs:\n",
    "        new_root = f\"{AUG_DIR}/{root[5:]}/{dir}\"\n",
    "        if not path.exists(new_root):\n",
    "           os.makedirs(new_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.io as io\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class OCRDataset(Dataset):\n",
    "    def __init__(self, dataset_dir, labels_dir, transform, device=None):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "        self.df = self.build_df()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get file name + text\n",
    "        file_name = self.df[\"file_name\"][idx]\n",
    "        # prepare image (i.e. resize + normalize)\n",
    "        # img = io.read_image(\n",
    "        #     path.join(self.dataset_dir, file_name))\n",
    "        # if self.device:\n",
    "        #     img.to(self.device)\n",
    "        # if self.transform:\n",
    "        #     img = self.transform(img)\n",
    "        # return (file_name, img)\n",
    "        text = self.df[\"text\"][idx]\n",
    "        return (file_name, text)\n",
    "\n",
    "    def build_df(self):\n",
    "        li = []\n",
    "        for root, dirs, files in os.walk(self.labels_dir):\n",
    "            for file in files:  # Loop through the dataset tsvfiles\n",
    "                if not file.endswith(\".tsv\"):\n",
    "                    continue\n",
    "\n",
    "                print(f\"Processing {file}\")\n",
    "                li.append(pd.read_table(path.join(root, file),\n",
    "                          names=[\"file_name\", \"text\"]))\n",
    "\n",
    "        return pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dotin13/mijo/GitHub/hand-syn/tang-syn/venv/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/dotin13/mijo/GitHub/hand-syn/tang-syn/venv/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing digit_95k.tsv\n",
      "Processing hand_line_all_548k.tsv\n",
      "Processing tang_syn_1577k.tsv\n",
      "Processing web_line_238k.tsv\n",
      "Processing hw_chinese_240k.tsv\n",
      "Processing hwdb_ic13_47k.tsv\n",
      "Processing hwdb2.1_13k.tsv\n",
      "Processing hwdb2.2_12k.tsv\n",
      "Processing hwdb2.0_16k.tsv\n",
      "Processing signatures_472k.tsv\n",
      "Processing hwdb2.0_4k.tsv\n",
      "Processing hwdb_ic13_3k.tsv\n",
      "Processing hw_chinese_17k.tsv\n",
      "Processing hwdb2.2_3k.tsv\n",
      "Processing hwdb2.1_3k.tsv\n",
      "Processing hwdb_ic13_val_5k.tsv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torchvision.transforms.v2 import InterpolationMode\n",
    "\n",
    "LABELS_DIR = \"dataset/labels\"\n",
    "DATA_DIR = \"dataset/data\"\n",
    "AUG_DIR = \"dataset/aug\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(\n",
    "        (64, 1024), interpolation=InterpolationMode.BILINEAR, antialias=True),\n",
    "])\n",
    "\n",
    "dataset = OCRDataset(DATA_DIR, LABELS_DIR,\n",
    "                     transform=None, device=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 12878/12878 [00:12<00:00, 1048.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/signatures/539/494.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_aug import build_data_aug\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "LABELS_DIR = \"labels\"\n",
    "AUG_DIR = \"aug\"\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "batch_size = 256\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "transform = build_data_aug((64, 1024), \"train\", device=device)\n",
    "\n",
    "for batch in tqdm(data_loader):\n",
    "    for (file_name, text) in zip(*batch):\n",
    "        if not isinstance(text, str):\n",
    "            print(file_name)\n",
    "\n",
    "    # input_images = batch[1]\n",
    "    # transformed_batch = transform(input_images.to(device))\n",
    "    # for i, item in enumerate(transformed_batch):\n",
    "    #     img = item\n",
    "    #     save_image(img, path.join(AUG_DIR, batch[0][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">16</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span>AUG_DIR = <span style=\"color: #808000; text-decoration-color: #808000\">\"dataset/aug\"</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span>device = torch.device(<span style=\"color: #808000; text-decoration-color: #808000\">\"cuda\"</span>)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>16 tfm = build_data_aug(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">64</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"train\"</span>, device=device)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> root, dirs, files <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> os.walk(LABELS_DIR):                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> file <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> files:  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Loop through the dataset tsvfiles</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/dotin13/mijo/GitHub/hand-syn/tang-syn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data_aug.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">217</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">build_data_aug</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>transforms.ConvertImageDtype(dtype=torch.float32),                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">215 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>transforms.RandomChoice([                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">216 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># WeightedRandomChoice([</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>217 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># transforms.RandomHorizontalFlip(p=1),</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">218 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>transforms.RandomRotation(degrees=(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span>),                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │     </span>expand=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">220 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │     </span>fill=(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)),                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'int'</span> object is not subscriptable\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m16\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0mAUG_DIR = \u001b[33m\"\u001b[0m\u001b[33mdataset/aug\u001b[0m\u001b[33m\"\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0mdevice = torch.device(\u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m)                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m16 tfm = build_data_aug(\u001b[94m64\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mtrain\u001b[0m\u001b[33m\"\u001b[0m, device=device)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[94mfor\u001b[0m root, dirs, files \u001b[95min\u001b[0m os.walk(LABELS_DIR):                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m file \u001b[95min\u001b[0m files:  \u001b[2m# Loop through the dataset tsvfiles\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/dotin13/mijo/GitHub/hand-syn/tang-syn/\u001b[0m\u001b[1;33mdata_aug.py\u001b[0m:\u001b[94m217\u001b[0m in \u001b[92mbuild_data_aug\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m214 \u001b[0m\u001b[2m│   │   │   \u001b[0mtransforms.ConvertImageDtype(dtype=torch.float32),                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m215 \u001b[0m\u001b[2m│   │   │   \u001b[0mtransforms.RandomChoice([                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m216 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# WeightedRandomChoice([\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m217 \u001b[2m│   │   │   │   \u001b[0m\u001b[2m# transforms.RandomHorizontalFlip(p=1),\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m218 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtransforms.RandomRotation(degrees=(-\u001b[94m10\u001b[0m, \u001b[94m10\u001b[0m),                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m219 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │     \u001b[0mexpand=\u001b[94mTrue\u001b[0m,                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m220 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │     \u001b[0mfill=(\u001b[94m1\u001b[0m, \u001b[94m1\u001b[0m, \u001b[94m1\u001b[0m)),                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[32m'int'\u001b[0m object is not subscriptable\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import torchvision.io as io\n",
    "from data_aug import build_data_aug\n",
    "\n",
    "\n",
    "LABELS_DIR = \"dataset/labels\"\n",
    "DATA_DIR = \"dataset/data\"\n",
    "AUG_DIR = \"dataset/aug\"\n",
    "\n",
    "# device = torch.device(\"cuda\")\n",
    "# tfm = build_data_aug(64, \"train\", device=device)\n",
    "\n",
    "for root, dirs, files in os.walk(LABELS_DIR):\n",
    "    for file in files:  # Loop through the dataset tsvfiles\n",
    "        if not file.endswith(\".tsv\"):\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {file}\")\n",
    "\n",
    "        with open(path.join(root, file), \"r\", encoding=\"utf-8\") as tsvfile:\n",
    "\n",
    "            for line in tqdm(tsvfile):  # Loop through lines in the tsvfile\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                image_file = line.split(\"\\t\")[0]\n",
    "                image_path = path.join(DATA_DIR, image_file)\n",
    "                if not path.exists(image_path):\n",
    "                    raise Exception(f\"Image file {image_file} not found\")\n",
    "\n",
    "                # aug_dir = path.join(AUG_DIR, \"/\".join(image_file.split(\"/\")[:-1]))\n",
    "                # if not path.exists(aug_dir):\n",
    "                #     os.makedirs(aug_dir)\n",
    "\n",
    "                # input_image = io.read_image(path.join(DATA_DIR, image_file))\n",
    "                # augmented = tfm(input_image.to(device))\n",
    "\n",
    "                # output_path = path.join(AUG_DIR, image_file)\n",
    "                # torchvision.utils.save_image(augmented, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"V2 Testing\"\"\"\n",
    "\n",
    "from torchvision.transforms import functional\n",
    "\n",
    "import torch\n",
    "import torchvision.io as io\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "from data_aug import build_data_aug\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "input_image = io.read_image(\"0.png\").unsqueeze(0).to(device)\n",
    "tfm = build_data_aug((64, 3072), \"train\", device=device)\n",
    "augmented = tfm(input_image)\n",
    "\n",
    "plt.imshow(functional.to_pil_image(augmented.cpu()[0]))\n",
    "\n",
    "# input_image = input_image.filter(ImageFilter.MinFilter(3))\n",
    "# plt.imshow(input_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"V1 Testing\"\"\"\n",
    "\n",
    "from torchvision.transforms import functional\n",
    "\n",
    "import torch\n",
    "import torchvision.io as io\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "from data_aug import build_data_aug\n",
    "\n",
    "input_image = Image.open(\"0.png\")\n",
    "tfm = build_data_aug(64, \"train\")\n",
    "augmented = tfm(input_image)\n",
    "\n",
    "# plt.imshow(functional.to_pil_image(augmented.cpu()[0]))\n",
    "\n",
    "# plt.imshow(augmented.cpu())\n",
    "\n",
    "plt.imshow(functional.to_pil_image(augmented))\n",
    "\n",
    "# input_image = input_image.filter(ImageFilter.MinFilter(3))\n",
    "# plt.imshow(input_image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
