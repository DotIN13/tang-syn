{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_text(text):\n",
    "    text_length = len(text)\n",
    "    split_lengths = []\n",
    "\n",
    "    while text_length > 0:\n",
    "        split_length = random.randint(1, 20)\n",
    "        split_lengths.append(split_length)\n",
    "        text_length -= split_length\n",
    "\n",
    "    start = 0\n",
    "    split_texts = []\n",
    "\n",
    "    for length in split_lengths:\n",
    "        split_texts.append(text[start:start + length])\n",
    "        start += length\n",
    "    \n",
    "    return split_texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process and save *苦难的年代* into textlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "\n",
    "\n",
    "with open(\"textlines/niandai-0.txt\", \"w\", encoding=\"utf-8\") as output:\n",
    "    for file in os.listdir(\"corpus\"):\n",
    "        if not file.endswith(\".pdf\"):\n",
    "            continue\n",
    "\n",
    "        with fitz.open(f\"corpus/{file}\") as doc:\n",
    "            for page in doc:\n",
    "                text = page.get_text(\"text\")\n",
    "                text = text.strip().replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "                if text:\n",
    "                    for seg in split_text(text):\n",
    "                        if random.random() > 0.8:\n",
    "                            seg = \"  \" + seg\n",
    "\n",
    "                        output.write(seg + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《苦难的年代》（第二十一章至第三十章）.pdf\n",
      "《苦难的年代》（第六十一章至第七十一章）.pdf\n",
      "《苦难的年代》（第三十一章至第四十章）.pdf\n",
      "《苦难的年代》（第四十一章至第五十章）.pdf\n",
      "《苦难的年代》（第五十一章至第六十章）.pdf\n",
      "《苦难的年代》（第十一章至第二十章）.pdf\n",
      "《苦难的年代》（第一章至第十章）.pdf\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import fitz\n",
    "\n",
    "LABELS_DIR = os.path.join(\"dataset_syn\", \"labels\", \"niandai\")\n",
    "INDEX_PATH = os.path.join(\"dataset_syn\", \"indexes\", \"niandai.tsv\")\n",
    "\n",
    "if not os.path.exists(LABELS_DIR):\n",
    "    os.makedirs(LABELS_DIR)\n",
    "\n",
    "with open(INDEX_PATH, \"w\", encoding=\"utf-8\") as index_file:\n",
    "    writer = csv.writer(index_file, delimiter='\\t', lineterminator='\\n')\n",
    "\n",
    "    file_idx = 0\n",
    "\n",
    "    for file in os.listdir(\"corpus\"):\n",
    "        print(file)\n",
    "\n",
    "        if not file.endswith(\".pdf\"):\n",
    "            continue\n",
    "\n",
    "        lines = []\n",
    "\n",
    "        with fitz.open(f\"corpus/{file}\") as doc:\n",
    "            for page in doc:\n",
    "                blocks = page.get_text(\"blocks\")\n",
    "                for block in blocks:\n",
    "                    text = block[4]\n",
    "                    text = text.strip().replace(\"\\n\", \"\")\n",
    "                    text = re.sub(r\"\\s+\", \" \", text)\n",
    "                    if text:\n",
    "                        lines.append(text)\n",
    "\n",
    "        if lines:\n",
    "            with open(os.path.join(LABELS_DIR, f\"niandai-{file_idx}.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"\\n\".join(lines))\n",
    "\n",
    "            relative_label_file_path = os.path.join(\n",
    "                \"niandai\", f\"niandai-{file_idx}.txt\")\n",
    "            writer.writerow([relative_label_file_path, len(lines)])\n",
    "\n",
    "            file_idx += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process poetry dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "POETRY_DATA = \"../poetry/data/\"\n",
    "\n",
    "\n",
    "def output_handle(num, output, current_output_index):\n",
    "    new_index = num // 50000\n",
    "\n",
    "    if output and current_output_index == new_index:\n",
    "        return current_output_index, output\n",
    "\n",
    "    if output:\n",
    "        output.close()\n",
    "\n",
    "    return new_index, open(f\"textlines/poetry-{new_index}.txt\",\n",
    "                           \"w\",\n",
    "                           encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def process_poetry():\n",
    "    num_lines = 0\n",
    "    output_index = 0\n",
    "    _, output = output_handle(num_lines, None, output_index)\n",
    "\n",
    "    for root, _dirs, files in os.walk(POETRY_DATA):\n",
    "        for file in files:\n",
    "            if not file.endswith(\".pt\"):\n",
    "                continue\n",
    "\n",
    "            with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as doc:\n",
    "                text = doc.read()\n",
    "                text = \"\".join(text.split(\"\\n\")[2:])\n",
    "                if text:\n",
    "                    for seg in split_text(text):\n",
    "                        if random.random() > 0.8:\n",
    "                            seg = \"  \" + seg\n",
    "\n",
    "                        output_index, output = output_handle(\n",
    "                            num_lines, output, output_index)\n",
    "                        output.write(seg + \"\\n\")\n",
    "                        num_lines += 1\n",
    "\n",
    "\n",
    "process_poetry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:26, 88.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:25, 88.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:18, 89.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:21, 89.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:26, 88.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:21, 89.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:17, 89.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:21, 89.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-8.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:01, 92.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-9.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:14, 90.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-10.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:14, 90.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-11.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:27, 88.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-12.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:22, 88.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-13.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:24, 88.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-14.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:21, 88.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-15.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:20, 89.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-16.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:22, 88.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-17.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:20, 89.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-18.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:21, 89.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-19.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:05, 91.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-20.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:23, 88.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-21.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:26, 88.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-22.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:28, 87.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-23.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:27, 88.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-24.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:18, 89.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-25.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:17, 89.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-26.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:17, 89.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-27.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:25, 88.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-28.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:34, 87.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-29.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [09:21, 89.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing poetry-30.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20660it [03:54, 88.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing niandai-0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57014it [10:05, 94.10it/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import ipyplot\n",
    "from PIL import Image, ImageFont\n",
    "from handright import Template, handwrite\n",
    "from itertools import product\n",
    "import concurrent.futures\n",
    "\n",
    "available_fonts = [\n",
    "    ImageFont.truetype(f\"fonts/{font}\", size=160)\n",
    "    for font in os.listdir(\"fonts\") if font.endswith((\".ttf\", \".otf\"))\n",
    "]\n",
    "fonts = lambda: random.choice(available_fonts)\n",
    "fills = lambda: tuple(random.choices(range(50), k=3))\n",
    "graph_outlines = lambda: tuple(random.choices(range(128), k=3))\n",
    "graph_widths = lambda: random.randint(2, 8)\n",
    "graph_papers = lambda min_chars: (random.randint(min_chars, 25), 1)\n",
    "margins = lambda: random.randint(0, 150)\n",
    "\n",
    "\n",
    "def construct_template(text):\n",
    "    min_chars = len(text)\n",
    "    args = {\n",
    "        \"font\": fonts(),\n",
    "        \"fill\": fills(),\n",
    "        \"graph_outline\": graph_outlines(),\n",
    "        \"graph_width\": graph_widths(),\n",
    "        \"graph_paper\": graph_papers(min_chars),\n",
    "        \"left_margin\": margins(),\n",
    "        \"top_margin\": margins(),\n",
    "        \"right_margin\": margins(),\n",
    "        \"bottom_margin\": margins(),\n",
    "    }\n",
    "\n",
    "    return Template(\n",
    "        **args,\n",
    "        background=Image.new(mode=\"RGB\", size=(200, 200), color=\"#fff\"),\n",
    "        line_spacing_sigma=4,  # 行间距随机扰动\n",
    "        font_size_sigma=2,  # 字体大小随机扰动\n",
    "        word_spacing_sigma=4,  # 字间距随机扰动\n",
    "        # start_chars=\"“（[<\",  # 特定字符提前换行，防止出现在行尾\n",
    "        # end_chars=\"，。\",  # 防止特定字符因排版算法的自动换行而出现在行首\n",
    "        perturb_x_sigma=4,  # 笔画横向偏移随机扰动\n",
    "        perturb_y_sigma=6,  # 笔画纵向偏移随机扰动\n",
    "        perturb_theta_sigma=0.05,  # 笔画旋转偏移随机扰动\n",
    "        single_line=True,\n",
    "        features=set([1]))\n",
    "\n",
    "\n",
    "def draw_line(data):\n",
    "    file, line, i = data\n",
    "    if not line:\n",
    "        return (file, [], i)\n",
    "\n",
    "    images = list(handwrite(line, construct_template(line)))\n",
    "    return (file, images, i)\n",
    "\n",
    "\n",
    "def textlines(file):\n",
    "    for i, line in enumerate(open(file, \"r\", encoding=\"utf-8\")):\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        yield (file, line, i)\n",
    "\n",
    "\n",
    "def generate_data():\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        for file in os.listdir(TEXTLINES_DIR):\n",
    "            print(f\"Processing {file}\")\n",
    "            output_dir = f\"output/{file[:-4]}\"\n",
    "            input_file = os.path.join(TEXTLINES_DIR, file)\n",
    "\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            if not file.endswith(\".txt\"):\n",
    "                continue\n",
    "\n",
    "            for res in tqdm(executor.map(draw_line, textlines(input_file), chunksize=3)):\n",
    "                _file, images, i = res\n",
    "                for im in images:\n",
    "                    im.save(f\"{output_dir}/{i}.jpg\")\n",
    "\n",
    "\n",
    "TEXTLINES_DIR = \"textlines\"\n",
    "generate_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:00, 320336.78it/s]\n",
      "50000it [00:00, 334265.55it/s]\n",
      "50000it [00:00, 325044.60it/s]\n",
      "50000it [00:00, 327158.59it/s]\n",
      "50000it [00:00, 324450.20it/s]\n",
      "50000it [00:00, 333017.12it/s]\n",
      "50000it [00:00, 334381.74it/s]\n",
      "50000it [00:00, 339411.44it/s]\n",
      "50000it [00:00, 339329.61it/s]\n",
      "50000it [00:00, 339814.57it/s]\n",
      "50000it [00:00, 342950.96it/s]\n",
      "50000it [00:00, 341700.95it/s]\n",
      "50000it [00:00, 333677.86it/s]\n",
      "50000it [00:00, 341433.36it/s]\n",
      "50000it [00:00, 333471.99it/s]\n",
      "50000it [00:00, 335712.44it/s]\n",
      "50000it [00:00, 335487.96it/s]\n",
      "50000it [00:00, 341806.21it/s]\n",
      "50000it [00:00, 341016.96it/s]\n",
      "50000it [00:00, 337007.74it/s]\n",
      "50000it [00:00, 331812.62it/s]\n",
      "50000it [00:00, 342474.36it/s]\n",
      "50000it [00:00, 339945.11it/s]\n",
      "50000it [00:00, 343602.20it/s]\n",
      "50000it [00:00, 342594.08it/s]\n",
      "50000it [00:00, 345254.53it/s]\n",
      "50000it [00:00, 345018.24it/s]\n",
      "50000it [00:00, 338480.71it/s]\n",
      "50000it [00:00, 334829.66it/s]\n",
      "50000it [00:00, 327575.59it/s]\n",
      "20660it [00:00, 329578.10it/s]\n",
      "57014it [00:00, 335353.27it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "TEXTLINES_DIR = \"textlines\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "\n",
    "with open(f'tang-syn-labels.tsv', 'w', newline='') as tsvfile:\n",
    "    writer = csv.writer(tsvfile, delimiter='\\t', lineterminator='\\n')\n",
    "\n",
    "    for file in os.listdir(TEXTLINES_DIR):\n",
    "        image_dir = file[:-4]\n",
    "\n",
    "        with open(os.path.join(TEXTLINES_DIR, file), \"r\", encoding=\"utf-8\") as f:\n",
    "            for i, line in enumerate(tqdm(f)):\n",
    "\n",
    "                if not os.path.exists(os.path.join(OUTPUT_DIR, image_dir, f\"{i}.jpg\")):\n",
    "                    print(f\"{image_dir}/{i}.jpg not found\")\n",
    "                    continue\n",
    "\n",
    "                writer.writerow([f\"{image_dir}/{i}.jpg\", line.replace(\"\\n\", \"\")])\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
